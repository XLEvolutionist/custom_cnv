---
title: "Custom CNV Calling"
author: "Simon Renny-Byfield"
date: "February 23, 2015"
output: html_document
---

##Introduction##
After trying several programs trying to call CNV, we have been pretty dissatisfied with the output. Generally, the programs do not run samples together in one run, do not produce similar results with varying parameters, or true positive (TP) and false positive (FP) [as a percentage] track each other perfectly (i.e. calls are more or less random; estimates are based on a "Gold Standard" of the Swanson-Wagner CNV CGH Chip).

Jeff and I decided to try writing something on our own. The approach is a simple one and there are several points to make before we begin. We will:

* Focusing on genes, seeing as this is where we can call most of the SNPs anyway.
* Use read-depth (normalized) per million per kb of gene, to inform copy number.
* Also adjust coverage to GC content of the gene.
* Take advantage of B73 as a reference sample.

##Generating the coverage data##
The first task is to generate coverage data for each gene. Jeff and I decided to use strict mapping criteria, I filtered with samtools with `-MINMAPQ 30`, using something that looks like this:
<br>
<br/>
`
samtools view -bhq 30 ../$file > filtered_$file
`
<br>
<br/>
The data used are stored in `/group/jrigrp4/cn.mops/data/filtered_bams` and have been filtered to **minimum map quality of 30**. Subsequent to filtering the data I then used [`bedtools`](http://bedtools.readthedocs.org/en/latest/) to generate coverage data. This is relatively easy with a simple one liner using the `multicov` call. The following bedtools run was executed from within the dir `/group/jrigrp4/cn.mops/data/filtered_bams`.
<br>
<br/>
`
bedtools multicov -bams *.bam -bed ../../../freec/maize3/GeneZeaRefV3.bed -q 30 > coverage.per.gene.txt
`
<br>
<br/>
In order to find which column is which, I grabbed the output of `ls *.bam`, giving:
<br>
<br/>

```{r, eval=FALSE, echo = TRUE}
 15G -rw-rw-r-- 1 sbyfield jrigrp  15G Feb 23 21:56 filtered_B73.bam
 20G -rw-rw-r-- 1 sbyfield jrigrp  20G Feb  2 14:39 filtered_JRIAL2A.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 14:21 filtered_JRIAL2B.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 14:15 filtered_JRIAL2C.sorted.bam
 21G -rw-rw-r-- 1 sbyfield jrigrp  21G Feb  2 14:42 filtered_JRIAL2D.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 14:13 filtered_JRIAL2E.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 14:18 filtered_JRIAL2F.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 15:16 filtered_JRIAL2G.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 15:23 filtered_JRIAL2H.sorted.bam
 21G -rw-rw-r-- 1 sbyfield jrigrp  21G Feb  2 15:41 filtered_JRIAL2I.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 15:10 filtered_JRIAL2J.sorted.bam
 19G -rw-rw-r-- 1 sbyfield jrigrp  19G Feb  2 16:11 filtered_JRIAL2K.sorted.bam
 19G -rw-rw-r-- 1 sbyfield jrigrp  19G Feb  2 16:12 filtered_JRIAL2L.sorted.bam
 19G -rw-rw-r-- 1 sbyfield jrigrp  19G Feb  2 16:14 filtered_JRIAL2M.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 16:00 filtered_JRIAL2N.sorted.bam
 16G -rw-rw-r-- 1 sbyfield jrigrp  16G Feb  2 16:07 filtered_JRIAL2O.sorted.bam
 16G -rw-rw-r-- 1 sbyfield jrigrp  16G Feb  2 16:16 filtered_JRIAL2P.sorted.bam
 20G -rw-rw-r-- 1 sbyfield jrigrp  20G Feb  2 16:51 filtered_JRIAL2Q.sorted.bam
 19G -rw-rw-r-- 1 sbyfield jrigrp  19G Feb  2 16:45 filtered_JRIAL2R.sorted.bam
 18G -rw-rw-r-- 1 sbyfield jrigrp  18G Feb  2 16:40 filtered_JRIAL2S.sorted.bam
 17G -rw-rw-r-- 1 sbyfield jrigrp  17G Feb  2 16:43 filtered_JRIAL2T.sorted.bam
8.2G -rw-rw-r-- 1 sbyfield jrigrp 8.2G Feb  2 16:00 filtered_TIL01_sorted.bam
```

The output of the `bedtools` call was the normalized according to this [script](https://github.com/XLEvolutionist/custom_cnv/blob/master/gene_depth.R). Briefly this involves normalizing by library size and gene size giving mapped reads per million per kb.

##Assesing the data##

We will now load in the data from GitHub (should work for anyone) and produce a few diagnostic plots:
```{r,message=FALSE,warning=FALSE}
# load in some libraries
library(RCurl)
library(data.table)
library(ggplot2)
library(reshape2)
library(scales)
library(EDASeq)
library(gplots)
# import the data from GitHub
url<-"https://raw.githubusercontent.com/XLEvolutionist/custom_cnv/master/data/normDepth.txt"
data <- getURL(url,
               ssl.verifypeer=0L, followlocation=1L)
writeLines(data,'~/temp.txt')
norm.df<-read.table("~/temp.txt",header=TRUE)
norm.df<-data.table(norm.df)
```

The next part of the analysis is to look at the distribution of read coverage for all samples:
```{r}
hist(x=melt(subset(norm.df,select=-c(1:4,27,28)))$value, main="coverge (all samples)", 
      xlim=c(0,50), xlab="normalized coverage per kb",col="grey",cex.lab=1.6, breaks=5000)
```

At this stage it important to see what the distribution of this coverage is in the reference B73. Any genes that have 0 (or nearly zero) coverage in B73 should be removed. The zero is likely due to bad mapping rather than real missing data, and so we cannot trust RD estimates of these genes in the teosinte lines.

```{r}
hist(x=subset(norm.df,select="B73.bam")$B73.bam, main="coverage in B73",
      xlim=c(0,50), xlab="normalized coverage per kb",col="grey",cex.lab=1.6, breaks=100)
```

So, many genes in b73 have zero read coverage. Thus we cannot trust estimates of CNVs over these genes and they should be removed from the analysis. We can use whatever cut-off we like but here I am picking 2 mapped reads per million per kb (mpmk). Filtering the reads happens like this:

```{r,echo=FALSE}
# remove any genes with count less that one in B73
norm.df<-subset(norm.df,subset=norm.df$B73.bam > 1)
norm.df<-subset(norm.df,subset=norm.df$B73.bam < 15)
#remove any strange genes with super high coverage, in any sample
norm.df<-subset(norm.df,subset=apply(subset(norm.df, select=-c(1:4,27,28)),1,function(x) max(x)) < 100)
```

Now, lets have another look at the distribution in B73:

```{r, echo = FALSE}
#look ant the distribution of coverage in b73
hist(norm.df$B73.bam, breaks=50, col="grey", main ="B73 trimmed",
     xlab="normalized coverage per kb",cex.lab=1.6, xlim=c(0,30))
```

##GC content and adjustment with loess smoothing##

So far the data look pretty good but how does GC content impact the RD estimates? It can be easily seen that GC content (already a known bias in Illumina data) can impact coverage. Here I plot GC content as a predictor of read depth over genes, using TIL01 as the sample:

```{r}
plot(norm.df$pct_gc,log(norm.df$TIL01), main="GC content and coverage", xlab="GC content (fraction)", ylab="log(mrmk)",col = alpha("cornflowerblue", 0.3), cex = 0.1,xlim=c(0.15,0.9))
```

Now produce the smoothed data with the `loess()` function of R. **Note** After some online research I found an R module called [`EDASeq`](http://bioconductor.org/packages/release/bioc/html/EDASeq.html) which can use loess smoothing to normalize counts within a library. You can use the `withinLaneNormalization` method to adjust count data according to GC content.  

```{r, echo=TRUE, eval = FALSE}
# subset the data.frame
countData<-subset(norm.df,select=-c(1:4,27,28))
# turn it into a matrix
countData<-as.matrix(countData)
# head(countData)
# now try to normalize the data according to GC content
gcNorm<-withinLaneNormalization(x=countData, y=norm.df$pct_gc, which="loess", round=FALSE)
# modify make a new data.table of the gc normalized counts
gcNorm<-data.table(gcNorm)

save(gcNorm, file="~/gcNorm.RData")
```

The above is not executed but the outcome has been saved and is now loaded:
```{r}
load("~/gcNorm.RData")
gcNorm<-cbind(subset(norm.df,select=c(1:4)),gcNorm,subset(norm.df, select=c(27,28)))
#head(gcNorm)
```

So the function `withinLaneNormalization` does: "The loess normalization transforms the data by regressing the counts on `y` and subtracting the loess fit from the counts to remove the dependence." So we have removed the dependence of coverage on GC content. But what does the plot look like?

```{r}
plot(gcNorm$pct_gc,log(gcNorm$TIL01), main="GC content and GC normalized coverage", xlab="GC content (fraction)", ylab="log(mrmk)",col = alpha("cornflowerblue", 0.3), cex = 0.1, xlim=c(0.15,0.9))
```

This looks good! But the next question is to ask what about the distribution of read-depth subsequent to gc normalization:
```{r}
hist(gcNorm$B73.bam, col="grey", main ="B73 GC normalized",
     xlab="normalized coverage per kb",cex.lab=1.6, breaks = 200, xlim=c(0,50))
```

##Comparing CNV calls##

Now lets take a look at the distribution of read counts in `TIL01`, and see where the genes that are called as CNV in the Swanson-Wagner paper. This is done by sub-setting the data to just those with CNV calls in TIL01 (using data.table) as such, targeting the down CNVs first. Each vertical line is a CNV call.
```{r}
# first load in the Swanson-Wagner data.
# import the data from GitHub
url<-"https://raw.githubusercontent.com/XLEvolutionist/custom_cnv/master/data/SW_cnv_calls.csv"
data <- getURL(url,
               ssl.verifypeer=0L, followlocation=1L)
writeLines(data,'~/SW.csv')
sw.df<-read.csv("~/SW.csv",header=TRUE)
sw.df<-data.table(sw.df)
# remove those genes not on the main scaffolds
sw.df<-subset(sw.df,subset=Chromosome != "chrUN")
# head(sw.df)
# now grab all those genes that are not normal (i.e.  not 0)
TIL.genes<-subset(sw.df,subset=sw.df$TIL1 != 0, select=c(GeneID,TIL1))
TIL.up<-subset(sw.df,subset=sw.df$TIL1 == 1, select=c(GeneID,TIL1))
TIL.down<-subset(sw.df,subset=sw.df$TIL1 == -1, select=c(GeneID,TIL1))

# grab the coverage data for those genes with CNV calls
coverage_sw<-subset(gcNorm,subset=name %in% TIL.genes$GeneID)
# grab the coverage data for those genes with CNV calls
down_sw<-subset(gcNorm,subset=name %in% TIL.down$GeneID, select=c(TIL01,B73.bam))
# grab the coverage data for those genes with CNV calls
up_sw<-subset(gcNorm,subset=name %in% TIL.up$GeneID,select=c(TIL01,B73.bam))
dim(coverage_sw)
dim(TIL.genes)

# plot a histgoram of TIL1
hist(gcNorm$TIL01, main ="TIL01 read-depth",
     xlab="normalized coverage per kb",cex.lab=1.6, breaks = 500, xlim=c(0,40))
abline(v=down_sw$TIL01,lwd= 0.1,xpd=FALSE,col = "blue")
```

And now how about the up CNVs?:

```{r}
hist(gcNorm$TIL01, main ="TIL01 read-depth",
     xlab="normalized coverage per kb",cex.lab=1.6, breaks = 500, xlim=c(0,40))
abline(v=up_sw$TIL01,lwd= 0.1,xpd=FALSE,col="red")
```

Now what about the distribution of coverage for the Swanson-Wagner CNV calls:

```{r}
# make a ggplot data.table
all<-data.frame("depth"=log(c(as.numeric(up_sw$TIL01)+1,as.numeric(down_sw$TIL01)+1)),"call"=c(rep("up",length(up_sw$TIL01)),rep("down",length(down_sw$TIL01))))
max(as.numeric(all$depth))
ggplot(all, aes(x=depth)) +
  geom_histogram(data=subset(all,subset=call =="up"), fill="red",alpha = 0.2) +
  geom_histogram(data=subset(all,subset=call =="down"), fill="blue",alpha = 0.2) +
  xlab("log(depth+1)")
  #geom_density(data=subset(all,subset=call =="up"), fill="red",alpha = 0.2) +
  #geom_density(data=subset(all,subset=call =="down"), fill="blue",alpha = 0.2) +
```

##Trying a differnet approach##

So, it appears as though both approaches (read-depth vs chip) do not jive with one another. Oh dear...

Another possibility is to normalize coverage in TIL01 (and the Palmar Chico pop) with the observed coverage in the B73 reference. If you look at the coverage in B73 vs TIL01, and ask where are the CNVs, you might see an interesting pattern:

```{r}
plot(gcNorm$B73.bam,gcNorm$TIL01, log="xy", cex=0.4, col=alpha("grey",0.5), xlab="log(normalized coverage in B73)",
      ylab="log(normalized coverage in TIL01)")
abline(0,1)
points(down_sw$B73.bam,down_sw$TIL01, col = "blue", cex=0.5)
points(up_sw$B73.bam,up_sw$TIL01, col = "red", cex=0.5)
legend(x="topright",legend=c("down","up"), col=c("blue","red"), pch = 1)
```

Most of the down CNV calls from Swanson-Wagner have lower coverage in TIL01 (at least that is somewhat re-assuring) and have "typical" coverage in B73, but sometimes much lower coverage in TIL01. The next interesting aspect of the data is to ask "what is the distribution of differences in TIL01 and B73", that is `B73/TIL01`.

```{r}
hist(log(gcNorm$TIL01/gcNorm$B73.bam), xlab="coverage difference (TIL01/B73)", col= "grey", main ="", breaks=200)
abline(v=log(down_sw$TIL01/down_sw$B73.bam), col = "blue", lwd=0.15)
abline(v=log(up_sw$TIL01/up_sw$B73.bam), col = "red", lwd=0.15)
hist(log((gcNorm$TIL01/gcNorm$B73.bam)), xlab="coverage ratio (TIL01/B73)", col= alpha("grey",0.9), main ="", breaks=200, add=TRUE)
abline(v=log(1), col = "black", lwd=5, lty = "dashed")
```

And one further question, what is the distribution of CNV calls, seperately for up and down?
```{r}
hist(log(down_sw$TIL01/down_sw$B73.bam), xlab="coverage ratio (TIL01/B73) over CNV", col= alpha("blue",0.3), main ="", breaks=40, xlim=c(-6,4))
hist(log(up_sw$TIL01/up_sw$B73.bam), xlab="coverage ratio (TIL01/B73) over CNV", col= alpha("red",0.3), main ="", breaks=40, add=TRUE)
legend(x="topright",legend=c("down","up"), col=c(alpha("blue",0.3),alpha("red",0.6)), pch = 15)
abline(v=log(1), col = "black", lwd=5, lty = "dashed")
```

There is some overlap between the two distributions, but *up* CNV seem to be skewed to the right compared to *down* CNV. If we assume that most genes are in equal copy number in the reference (B73) and TIL01 then we can use standard deviations away from the mean to make a cut of of copy-number change. *Note* that the mean is not 0 (the log of 1, indicatin equal coverage in both TIL01 and B73), but is skewed lower than zero. This is morethan likely due to polymorphisms in TIL01 (relative to B73) preventung perfect mapping or reads and a slight reduction in read-depth.  As in [Zhou et al](http://www.nature.com/nbt/journal/vaop/ncurrent/full/nbt.3096.html#supplementary-information) we can use:

```{r}
# calculate our CNV limit based on FDR corrected p value
limit<-qnorm(0.025/(dim(gcNorm)[1]),lower.tail=FALSE)
```

* down CNV < mean x `r limit` stdev (correcting for FDR of 0.05)
* up CNV > mean x `r limit` stdev (correcting for FDR of 0.05)

using the mean of the coverage ratio (TIL01/B73).
```{r}
ratio<-gcNorm$TIL01/gcNorm$B73.bam
stdev<-sd(ratio)
# so you have to be more than limit*stdev away from the mean to be called CNV
linePos<-log(mean(ratio)+(limit*stdev))
hist(log(gcNorm$TIL01/gcNorm$B73.bam), xlab="log(coverage difference (TIL01/B73))", col= "grey", main ="", breaks=200)
abline(v=log(mean(ratio))-linePos, col = "black", lwd=1, lty = "dashed",lend=1)
abline(v=log(mean(ratio))+linePos, col = "black", lwd=1, lty = "dashed",lend=1)
abline(v=log(mean(ratio)), col = "black", lwd=3, lty = "solid",lend=1)
```

The solid line is the mean, and the two dashed lines represent the proposed CNV cut offs for up and down CNV.

##Now see what these distribution look like in Palmar Chico##

The next set of graphs will not be printed to screen but saved into a pdf, one graph for each of our 20 Palmar Chico lines (and TIL01 too). It is important to remember that these Palmar Chico lines are typically not inbred like the TIL01 lines used in the ground truthing section.

So the first step is to grab the sample names:
```{r}
samples<-colnames(gcNorm)[-c(1:4,27,28)]
```

I firstly want to check if the distribution of coverage is sensible in the 20 Palmar Chico lines...
```{r}
# make a matrix of 0, representing the "no evidence of change in copy-number"
cnv.mat<-matrix(data=0,nrow=dim(gcNorm)[1],ncol=length(samples))
rownames(cnv.mat)<-gcNorm$name
colnames(cnv.mat)<-samples
# head(cnv.mat)
# open up a pdf and print the histograms
pdf("samples_covergae.pdf")
par(mfrow=c(3,2))
# cycle through the samples
for ( s in samples ) {
  # print(s)
  # subset the data
  sub.df<-subset(gcNorm,select=c(s,"name"))
  sub.df<-data.frame(sub.df)
  # print(head(sub.df))
  hist(sub.df[,s], main =paste0(s, " read-depth"),
     xlab="normalized coverage per kb",cex.lab=1.4, breaks = c(seq(0,20,0.2),20.00001,max(sub.df[,s])), xlim=c(0,21), 
     col = alpha("cornflowerblue",0.5),border=alpha("cornflowerblue",0.7))
  # calculate the ratio between sample and reference"
  ratio<-sub.df[,s]/subset(gcNorm,select="B73.bam")
  ratio<-data.matrix(ratio)
  # print(max(ratio))
  # plot the ratio as a histogram
  hist(log(ratio), main=paste0(s," ratio (sample/ref)"),
     cex.lab=1.4, xlab="log(coverage difference (sample/ref))", col=alpha("cornflowerblue",0.4),
     border=alpha("cornflowerblue",0.4), breaks=200)
  # calculate the CNV "limit"
  stdev<-sd(ratio)
  limit<-qnorm(0.025/(dim(gcNorm)[1]),lower.tail=FALSE)
  linePos<-log(mean(ratio)+(limit*stdev))
  abline(v=log(mean(ratio))-linePos, col = "black", lwd=1, lty = "dashed",lend=1)
  abline(v=log(mean(ratio))+linePos, col = "black", lwd=1, lty = "dashed",lend=1)
  abline(v=log(mean(ratio)), col = "black", lwd=2, lty = "solid",lend=1)
  #turn sub.df back into a data.table
  sub.df<-data.table(sub.df,ratio)
  # call up CNV
  up<-subset(sub.df,subset=log(sub.df$B73.bam) > log(mean(ratio))+linePos)
  cnv.mat[rownames(cnv.mat) %in% up$name,s]<-1
  down<-subset(sub.df,subset=log(sub.df$B73.bam) < log(mean(ratio))-linePos)
  cnv.mat[rownames(cnv.mat) %in% down$name,s]<--1
}
dev.off()
# remove B73...
cnv.mat<-cnv.mat[,-1]
# remove all rows with zero
cnv.mat<-cnv.mat[apply(cnv.mat,1,function(x) !all(x == 0)),]
# head(cnv.mat)
heatmap.2(cnv.mat, trace="none",key.title ="",density.info="none",labRow="",col=c("mediumblue","black","red3"))
```

##Where are these CNVs in the genome?##